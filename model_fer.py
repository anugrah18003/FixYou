# -*- coding: utf-8 -*-
"""Model_FER.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GEpO2dhwUsPyO3rTkrmY5LztKLiiGezY

#Direktori Dari G-drive, **Skip kalau ga pake Drive**
"""

from google.colab import drive
drive.mount('/content/gdrive')

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"
# /content/gdrive/My Drive/Kaggle is the path where kaggle.json is present in the Google Drive

# Commented out IPython magic to ensure Python compatibility.
#changing the working directory
# %cd /content/gdrive/My Drive/Kaggle
#Check the present working directory using pwd command

"""#Ambil Data dari Kaggle"""

!kaggle datasets download -d deadskull7/fer2013

#unzipping the zip files and deleting the zip files
!unzip \*.zip  && rm *.zip

"""#Membuat Model Prediksi"""

import tensorflow as tf
import keras 
from keras.models import Sequential
from keras.layers import Dense,Flatten,Dropout
from keras.layers.convolutional import Conv2D,MaxPooling2D
from keras.layers.normalization import BatchNormalization
from keras.preprocessing.image import ImageDataGenerator ,load_img

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
import random

#Importing Data from CSV file
fer2013=pd.read_csv("fer2013.csv")

labels=fer2013.iloc[:,[0]].values

pixels=fer2013['pixels']

#Facial Expressions
Ekspresi={0:"Marah",1:"Jijik",2:"Takut",3:"Senang",4:"Sedih",5:"Terkejut",6:"Netral"}
from keras.utils import to_categorical 
labels = to_categorical(labels,len(Ekspresi))

#converting pixels to Gray Scale images of 48X48 
image = np.array([np.fromstring(pixel, dtype=int, sep=" ")for pixel in pixels])
image = image/255.0
image = image.reshape(image.shape[0],48,48,1).astype('float32')

plt.imshow(image[0][:,:,0])
Ekspresi[labels[0][0]]

#splitting data into training and test data
train_features,test_features,train_labels,test_labels = train_test_split(image,labels,test_size=0.2,random_state=0)

train_labels

def cnn_model(classes):
    model = Sequential()
    model.add(Conv2D(32,kernel_size=(3,3),strides=(1,1),activation='relu',input_shape=(48,48,1)))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))
    model.add(Dropout(0.25))
    
    model.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))
    model.add(Dropout(0.25))#to prevent neural network from overfitting
    
    model.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))
    model.add(Dropout(0.25))
    
    model.add(Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),activation='relu'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))
    model.add(Dropout(0.25))
    
    model.add(Flatten())
    
    model.add(Dense(256,activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.25))
    
    model.add(Dense(512,activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.25))
    
    model.add(Dense(classes,activation='softmax'))
    
    
    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])
    
    return model

classes=7
model = cnn_model(classes)
model.summary()

#train the CNN 
model.fit(train_features,train_labels,batch_size=105,epochs=40,verbose=2)

#Saving the  model to  use it later on
fer_json = model.to_json()
with open("fer.json", "w") as json_file:
    json_file.write(fer_json)
model.save_weights("fer.h5")